{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Lyrics Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "* Scrape lyrics from lyrics.com and save them on hard drive\n",
    "* Load lyrics into corpus\n",
    "* Create vectors for bag-of-words approach\n",
    "* Train models on lyrics\n",
    "* Predict artist of song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other artists: \"Peaches\", \"Barbra Streisand\", \"Britney Spears\", \"The Velvet Underground\"\n",
    "ARTISTS = [\n",
    "    \"Peaches\",\n",
    "    \"Barbra Streisand\",\n",
    "    \"Britney Spears\",\n",
    "]  \n",
    "\n",
    "\n",
    "def clean_my_song(song, model):\n",
    "    # parse the song through the spacy model\n",
    "    tokenised_song = model(song)\n",
    "    clean_song = \"\"\n",
    "    # loop through words, drop stop words\n",
    "    for word in tokenised_song:\n",
    "        if not word.is_stop:\n",
    "            clean_song += word.lemma_ + \" \"\n",
    "    # return the lemmatized version to the call\n",
    "    return clean_song.strip()\n",
    "\n",
    "\n",
    "def create_lyrics_corpus(artists):\n",
    "    \"\"\"loads song texts from files and stores lyrics and artist index in seperate lists\"\"\"\n",
    "    complete_lyrics = []\n",
    "    indices = []\n",
    "    for i, artist in enumerate(ARTISTS):\n",
    "        directory = f\"lyrics/{artist.lower().replace(' ', '-')}-lyrics\"\n",
    "        allfiles = os.listdir(directory)\n",
    "        all_lyrics = []\n",
    "        for file in allfiles:\n",
    "            with open(directory + \"/\" + file, \"r\", encoding=\"utf-8\") as f:\n",
    "                song_lyrics = f.read()\n",
    "                all_lyrics.append(song_lyrics)\n",
    "                all_lyrics.append(clean_my_song(song_lyrics, lang_model))\n",
    "        indices += [i] * len(all_lyrics)\n",
    "        print(artist, len(all_lyrics))\n",
    "        complete_lyrics += all_lyrics\n",
    "    return complete_lyrics, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peaches 67\n",
      "Barbra Streisand 428\n",
      "Britney Spears 152\n"
     ]
    }
   ],
   "source": [
    "# Store lists into variables, print out number of songs by artist\n",
    "complete_lyrics, indices = create_lyrics_corpus(ARTISTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=complete_lyrics, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('songs.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch scrub floor \\n scrubbin ' floor g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exuma \\n hear \\n got to time \\n Gettin ' start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening moonlight \\n mother finish work \\n sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love funny sad \\n quiet mad \\n good thing bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be get home , be get shoe \\n be get money , be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>touch , taste , breath , face \\n hand , head ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh , love \\n oh , yeah , yeah \\n oh , yeah \\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ooh hey , yeah \\n\\n hush , stop \\n , baby \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeah , smash radio bet , pen ! \\n Britney ( br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( Bangerz , fuckin ' bangerz ) \\n ( Bangerz , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   people watch scrub floor \\n scrubbin ' floor g...\n",
       "0   Exuma \\n hear \\n got to time \\n Gettin ' start...\n",
       "0   evening moonlight \\n mother finish work \\n sit...\n",
       "0   love funny sad \\n quiet mad \\n good thing bad ...\n",
       "0   be get home , be get shoe \\n be get money , be...\n",
       "..                                                ...\n",
       "3   touch , taste , breath , face \\n hand , head ,...\n",
       "3   oh , love \\n oh , yeah , yeah \\n oh , yeah \\n\\...\n",
       "3   ooh hey , yeah \\n\\n hush , stop \\n , baby \\n \\...\n",
       "3   yeah , smash radio bet , pen ! \\n Britney ( br...\n",
       "3   ( Bangerz , fuckin ' bangerz ) \\n ( Bangerz , ...\n",
       "\n",
       "[914 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('songs.csv', sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def vectors_and_df(complete_lyrics, indices):\n",
    "    \"\"\"creates vectors for songs and returns dataframe with songs as word vectors by all artists\"\"\"\n",
    "    cv = TfidfVectorizer(stop_words=\"english\")\n",
    "    cv.fit(complete_lyrics)\n",
    "    corpus_vecs = cv.transform(complete_lyrics)\n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=indices, columns=cv.get_feature_names()), cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0h</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>150</th>\n",
       "      <th>17</th>\n",
       "      <th>1776</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>2x</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>électrique</th>\n",
       "      <th>étaient</th>\n",
       "      <th>être</th>\n",
       "      <th>הו</th>\n",
       "      <th>יו</th>\n",
       "      <th>ימ</th>\n",
       "      <th>ירו</th>\n",
       "      <th>נו</th>\n",
       "      <th>עו</th>\n",
       "      <th>צו</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 5605 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0h   10   12  150   17  1776   20   24   2x   30  ...  électrique  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "..  ...  ...  ...  ...  ...   ...  ...  ...  ...  ...  ...         ...   \n",
       "2   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...         0.0   \n",
       "\n",
       "    étaient  être   הו   יו   ימ  ירו   נו   עו   צו  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..      ...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[647 rows x 5605 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(complete_lyrics, indices)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target column\n",
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "\n",
    "models_params = {\n",
    "    \"MultinomialNB\": {\"alpha\": 0.005},\n",
    "    \"CategoricalNB\": {\"alpha\": 0.01},\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 200,\n",
    "        \"max_features\": \"auto\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1,\n",
    "    },\n",
    "    \"LogisticRegression\": {\"C\": 1e6},\n",
    "}\n",
    "\n",
    "def train_models(models_params):\n",
    "    \"\"\"trains models on corpus and returns dataframe with scores\"\"\"\n",
    "    scores = {}\n",
    "    for model in models_params:\n",
    "        if model == \"LogisticRegression\":\n",
    "            m = LogisticRegression(**models_params[model])\n",
    "        elif model == \"RandomForestClassifier\":\n",
    "            m = RandomForestClassifier(**models_params[model])\n",
    "        elif model == \"MultinomialNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "        elif model == \"CategoricalNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "\n",
    "        m.fit(Xtrain, ytrain)\n",
    "        score_train = m.score(Xtrain, ytrain)\n",
    "        score_test = m.score(Xtest, ytest)\n",
    "        scores[f\"{model}\"] = {\n",
    "            \"params\": models_params[model],\n",
    "            \"train score\": score_train,\n",
    "            \"test score\": score_test,\n",
    "        }\n",
    "    return pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>{'alpha': 0.005}</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>0.792308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalNB</th>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 200, 'max_f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>{'C': 1000000.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   params  \\\n",
       "MultinomialNB                                            {'alpha': 0.005}   \n",
       "CategoricalNB                                             {'alpha': 0.01}   \n",
       "RandomForestClassifier  {'n_estimators': 500, 'max_depth': 200, 'max_f...   \n",
       "LogisticRegression                                       {'C': 1000000.0}   \n",
       "\n",
       "                       train score test score  \n",
       "MultinomialNB             0.992263   0.792308  \n",
       "CategoricalNB             0.992263   0.784615  \n",
       "RandomForestClassifier           1   0.746154  \n",
       "LogisticRegression               1   0.761538  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = train_models(models_params)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990726429675425"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on most promising model\n",
    "model = \"MultinomialNB\"\n",
    "m = MultinomialNB(**models_params[model])\n",
    "m.fit(X, y)\n",
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Elton John's \"Can you feel the love tonight\" for prediction\n",
    "new_song = [\n",
    "    \"\"\"\n",
    "    There's a calm surrender\n",
    "    To the rush of day\n",
    "    When the heat of a rolling wave\n",
    "    Can be turned away\n",
    "    An enchanted moment\n",
    "    And it sees me through\n",
    "    It's enough for this restless warrior\n",
    "    Just to be with you\n",
    "    And can you feel the love tonight?\n",
    "    It is where we are\n",
    "    It's enough for this wide-eyed wanderer\n",
    "    That we've got this far\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    How it's laid to rest?\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    There's a time for everyone\n",
    "    If they only learn\n",
    "    That the twisting kaleidoscope\n",
    "    Moves us all in turn\n",
    "    There's a rhyme and reason\n",
    "    To the wild outdoors\n",
    "    When the heart of this star-crossed voyager\n",
    "    Beats in time with yours\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    It is where we are\n",
    "    It's enough for this wide-eyed wanderer\n",
    "    That we've got this far\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    How it's laid to rest?\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_artist(song_lyrics):\n",
    "    \"\"\"predicts artist of song based on artists in corpus\"\"\"\n",
    "    # transform song into vector matrix\n",
    "    new_song_vecs = cv.transform(new_song)\n",
    "    ynew = new_song_vecs.todense()\n",
    "    \n",
    "    print(f\"This classifier predicts the song to be written by:\\n\")\n",
    "    for i, artist in enumerate(ARTISTS):\n",
    "        print(f\"{artist}: {round(m.predict_proba(ynew)[0][i] * 100, 1)}%.\")\n",
    "    song_pred = m.predict(ynew)[0]\n",
    "    confidence = m.predict_proba(ynew).max()\n",
    "    if confidence > 0.9:\n",
    "        confidence_word = \"definitely\"\n",
    "    elif confidence > 0.7:\n",
    "        confidence_word = \"probably\"\n",
    "    else:\n",
    "        confidence_word = \"maybe\"\n",
    "    print(f\"\\nThis song is {confidence_word} by {ARTISTS[song_pred]}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier predicts the song to be written by:\n",
      "\n",
      "Peaches: 0.0%.\n",
      "Barbra Streisand: 99.6%.\n",
      "Britney Spears: 0.4%.\n",
      "\n",
      "This song is definitely by Barbra Streisand!\n"
     ]
    }
   ],
   "source": [
    "predict_artist(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
