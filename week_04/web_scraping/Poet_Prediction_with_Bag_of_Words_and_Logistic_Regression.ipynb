{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Lyrics Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "* Scrape poems from lyrikline.org and save them on hard drive\n",
    "* Load poems into corpus\n",
    "* Create vectors for bag-of-words approach\n",
    "* Train models on poems\n",
    "* Predict poet of poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POETS = [\n",
    "    \"H. C. Artmann\",\n",
    "    \"Marcel Beyer\",\n",
    "    \"Nico Bleutge\",\n",
    "    \"Nora Bossong\",\n",
    "    \"Ann Cotten\",\n",
    "    \"Paul Celan\",\n",
    "    \"Oswald Egger\",\n",
    "    \"Durs Grünbein\",\n",
    "    \"Ernst Jandl\",\n",
    "    \"Thomas Kling\",\n",
    "    \"Friederike  Mayröcker\",\n",
    "    \"Monika Rinck\",\n",
    "    \"Ulf Stolterfoht\",\n",
    "    \"Uljana Wolf\",\n",
    "]\n",
    "\n",
    "\n",
    "def create_poems_corpus(poets):\n",
    "    \"\"\"loads song texts from files and stores lyrics and artist index in seperate lists\"\"\"\n",
    "    complete_poems = []\n",
    "    indices = []\n",
    "    for i, poet in enumerate(poets):\n",
    "        directory = f\"lyrik/{poet.lower().replace(' ', '_')}\" # lyrics ... -lyrics\n",
    "        allfiles = os.listdir(directory)\n",
    "        all_poems = []\n",
    "        for file in allfiles:\n",
    "            with open(directory + \"/\" + file, \"r\", encoding=\"utf-8\") as f:\n",
    "                poem = f.read()\n",
    "                all_poems.append(poem)\n",
    "        indices += [i] * len(all_poems)\n",
    "        print(poet, len(all_poems))\n",
    "        complete_poems += all_poems\n",
    "    return complete_poems, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H. C. Artmann 8\n",
      "Marcel Beyer 10\n",
      "Nico Bleutge 15\n",
      "Nora Bossong 10\n",
      "Ann Cotten 15\n",
      "Paul Celan 10\n",
      "Oswald Egger 10\n",
      "Durs Grünbein 10\n",
      "Ernst Jandl 10\n",
      "Thomas Kling 10\n",
      "Friederike  Mayröcker 10\n",
      "Monika Rinck 15\n",
      "Ulf Stolterfoht 15\n",
      "Uljana Wolf 14\n"
     ]
    }
   ],
   "source": [
    "# Store lists into variables, print out number of songs by artist\n",
    "complete_poems, indices = create_poems_corpus(POETS) # POETS or ARTISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = [\"a\",\"ab\",\"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"ander\",\"andere\",\"anderem\",\"anderen\",\"anderer\",\"anderes\",\"anderm\",\"andern\",\"anderr\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"ausserdem\",\"außer\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"besten\",\"bin\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"d.h\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darum\",\"darunter\",\"darüber\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"daß\",\"dein\",\"deine\",\"deinem\",\"deinen\",\"deiner\",\"deines\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"der\",\"deren\",\"derer\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"durfte\",\"durften\",\"dürfen\",\"dürft\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einig\",\"einige\",\"einigem\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"euer\",\"eure\",\"eurem\",\"euren\",\"eurer\",\"eures\",\"f\",\"folgende\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"grosse\",\"grossen\",\"grosser\",\"grosses\",\"groß\",\"große\",\"großen\",\"großer\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"hab\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"hätte\",\"hätten\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedes\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"keines\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"konnte\",\"konnten\",\"kurz\",\"können\",\"könnt\",\"könnte\",\"l\",\"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"machen\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"mal\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"mochten\",\"morgen\",\"muss\",\"musst\",\"musste\",\"mussten\",\"muß\",\"mußt\",\"möchte\",\"mögen\",\"möglich\",\"mögt\",\"müssen\",\"müsst\",\"müßt\",\"n\",\"na\",\"nach\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"soweit\",\"sowie\",\"später\",\"startseite\",\"statt\",\"steht\",\"suche\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"uhr\",\"um\",\"und\",\"uns\",\"unse\",\"unsem\",\"unsen\",\"unser\",\"unsere\",\"unserer\",\"unses\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"von\",\"vor\",\"w\",\"wahr\",\"wann\",\"war\",\"waren\",\"warst\",\"wart\",\"warum\",\"was\",\"weg\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wessen\",\"wie\",\"wieder\",\"wieso\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wissen\",\"wo\",\"woher\",\"wohin\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"wurden\",\"während\",\"währenddem\",\"währenddessen\",\"wäre\",\"würde\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"über\",\"überhaupt\",\"übrigens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def vectors_and_df(complete_poems, indices):\n",
    "    \"\"\"creates vectors for songs and returns dataframe with songs as word vectors by all artists\"\"\"\n",
    "    cv = TfidfVectorizer(stop_words=german)\n",
    "    cv.fit(complete_poems)\n",
    "    corpus_vecs = cv.transform(complete_poems)\n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=indices, columns=cv.get_feature_names()), cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>1499</th>\n",
       "      <th>20</th>\n",
       "      <th>200</th>\n",
       "      <th>30</th>\n",
       "      <th>3000ern</th>\n",
       "      <th>aar</th>\n",
       "      <th>abblend</th>\n",
       "      <th>abbruch</th>\n",
       "      <th>abbruchreif</th>\n",
       "      <th>...</th>\n",
       "      <th>überzeichnetem</th>\n",
       "      <th>überzeuge</th>\n",
       "      <th>überzogen</th>\n",
       "      <th>übrig</th>\n",
       "      <th>übrigblieb</th>\n",
       "      <th>üppigen</th>\n",
       "      <th>üppiger</th>\n",
       "      <th>все</th>\n",
       "      <th>жиды</th>\n",
       "      <th>поэты</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 7772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     10  1499   20  200   30  3000ern  aar  abblend  abbruch  abbruchreif  \\\n",
       "0   0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "0   0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "0   0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "0   0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "0   0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "..  ...   ...  ...  ...  ...      ...  ...      ...      ...          ...   \n",
       "13  0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "13  0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "13  0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "13  0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "13  0.0   0.0  0.0  0.0  0.0      0.0  0.0      0.0      0.0          0.0   \n",
       "\n",
       "    ...  überzeichnetem  überzeuge  überzogen  übrig  übrigblieb  üppigen  \\\n",
       "0   ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "0   ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "0   ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "0   ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "0   ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "..  ...             ...        ...        ...    ...         ...      ...   \n",
       "13  ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "13  ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "13  ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "13  ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "13  ...             0.0        0.0        0.0    0.0         0.0      0.0   \n",
       "\n",
       "    üppiger  все  жиды  поэты  \n",
       "0       0.0  0.0   0.0    0.0  \n",
       "0       0.0  0.0   0.0    0.0  \n",
       "0       0.0  0.0   0.0    0.0  \n",
       "0       0.0  0.0   0.0    0.0  \n",
       "0       0.0  0.0   0.0    0.0  \n",
       "..      ...  ...   ...    ...  \n",
       "13      0.0  0.0   0.0    0.0  \n",
       "13      0.0  0.0   0.0    0.0  \n",
       "13      0.0  0.0   0.0    0.0  \n",
       "13      0.0  0.0   0.0    0.0  \n",
       "13      0.0  0.0   0.0    0.0  \n",
       "\n",
       "[162 rows x 7772 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(complete_poems, indices)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target column\n",
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "\n",
    "models_params = {\n",
    "    \"MultinomialNB\": {},\n",
    "    \"CategoricalNB\": {},\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 200,\n",
    "        \"max_features\": \"auto\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1,\n",
    "    },\n",
    "    \"LogisticRegression\": {\"C\": 1e6},\n",
    "}\n",
    "\n",
    "def train_models(models_params):\n",
    "    \"\"\"trains models on corpus and returns dataframe with scores\"\"\"\n",
    "    scores = {}\n",
    "    for model in models_params:\n",
    "        if model == \"LogisticRegression\":\n",
    "            m = LogisticRegression(**models_params[model])\n",
    "        elif model == \"RandomForestClassifier\":\n",
    "            m = RandomForestClassifier(**models_params[model])\n",
    "        elif model == \"MultinomialNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "        elif model == \"CategoricalNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "\n",
    "        m.fit(Xtrain, ytrain)\n",
    "        score_train = m.score(Xtrain, ytrain)\n",
    "        score_test = m.score(Xtest, ytest)\n",
    "        scores[f\"{model}\"] = {\n",
    "            \"params\": models_params[model],\n",
    "            \"train score\": score_train,\n",
    "            \"test score\": score_test,\n",
    "        }\n",
    "    return pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalNB</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 200, 'max_f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>{'C': 1000000.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   params  \\\n",
       "MultinomialNB                                                          {}   \n",
       "CategoricalNB                                                          {}   \n",
       "RandomForestClassifier  {'n_estimators': 500, 'max_depth': 200, 'max_f...   \n",
       "LogisticRegression                                       {'C': 1000000.0}   \n",
       "\n",
       "                       train score test score  \n",
       "MultinomialNB             0.976744   0.212121  \n",
       "CategoricalNB             0.976744   0.212121  \n",
       "RandomForestClassifier           1  0.0909091  \n",
       "LogisticRegression               1   0.333333  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = train_models(models_params)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on most promising model\n",
    "model = \"LogisticRegression\"\n",
    "m = LogisticRegression(**models_params[model])\n",
    "m.fit(X, y)\n",
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Goethe's \"Osterspaziergang\" for prediction\n",
    "new_poem = [\n",
    "    \"\"\"\n",
    "    Vom Eise befreit sind Strom und Bäche\n",
    "    Durch des Frühlings holden, belebenden Blick,\n",
    "    Im Tale grünet Hoffnungsglück;\n",
    "    Der alte Winter, in seiner Schwäche,\n",
    "    Zog sich in rauhe Berge zurück.\n",
    "    Von dort her sendet er, fliehend, nur\n",
    "    Ohnmächtige Schauer körnigen Eises\n",
    "    In Streifen über die grünende Flur.\n",
    "    Aber die Sonne duldet kein Weißes,\n",
    "    Überall regt sich Bildung und Streben,\n",
    "    Alles will sie mit Farben beleben;\n",
    "    Doch an Blumen fehlts im Revier,\n",
    "    Sie nimmt geputzte Menschen dafür.\n",
    "    Kehre dich um, von diesen Höhen\n",
    "    Nach der Stadt zurück zu sehen!\n",
    "    Aus dem hohlen finstern Tor\n",
    "    Dringt ein buntes Gewimmel hervor.\n",
    "    Jeder sonnt sich heute so gern.\n",
    "    Sie feiern die Auferstehung des Herrn,\n",
    "    Denn sie sind selber auferstanden:\n",
    "    Aus niedriger Häuser dumpfen Gemächern,\n",
    "    Aus Handwerks- und Gewerbesbanden,\n",
    "    Aus dem Druck von Giebeln und Dächern,\n",
    "    Aus der Straßen quetschender Enge,\n",
    "    Aus der Kirchen ehrwürdiger Nacht\n",
    "    Sind sie alle ans Licht gebracht.\n",
    "    Sieh nur, sieh! wie behend sich die Menge\n",
    "    Durch die Gärten und Felder zerschlägt,\n",
    "    Wie der Fluß in Breit und Länge\n",
    "    So manchen lustigen Nachen bewegt,\n",
    "    Und, bis zum Sinken überladen,\n",
    "    Entfernt sich dieser letzte Kahn.\n",
    "    Selbst von des Berges fernen Pfaden\n",
    "    Blinken uns farbige Kleider an.\n",
    "    Ich höre schon des Dorfs Getümmel,\n",
    "    Hier ist des Volkes wahrer Himmel,\n",
    "    Zufrieden jauchzet groß und klein:\n",
    "    Hier bin ich Mensch, hier darf ichs sein!\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "new_poem2 = [\n",
    "    \"\"\"\n",
    "    Beete, hört nun kurz her, bitte. \n",
    "    Ich habe überlegt, diese Abhandlung in Versen zu schreiben. \n",
    "    Es düngte mich eine Weile eine gute Idee. \n",
    "    Die verschwand, zu recht, wie ich meine. \n",
    "    Verzeiht mir also die unregelmäßigen Zeilen, in denen ich mich euch aussetzen werde. \n",
    "    Es ist kaum was drin: eins für die Vögel, eins für die anderen Vögel, \n",
    "    eins für den Tod und eines, das möglicherweise überleben könnte. \n",
    "    Verzeiht. \n",
    "    Zu fette Witze schärfen zuweilen den Mulch, mit dem ich euch belegen wollte, \n",
    "    an die Grenze der Unannehmlichkeit, einer Art von Kratzen oder Schaben, \n",
    "    das mitunter auch zu merken ist, wenn Spaten an einem Stein vorbeigeht, \n",
    "    aber ich etwas tiefer davon haben will. \n",
    "    Das kennt ihr wohl oder übel gründlicher als ich. \n",
    "    Ich hoffe euer Mark zu erschüttern, \n",
    "    und wenn ich dabei in einen sich auftuenden Schacht trete \n",
    "    und mir im günstigsten Fall etwas verrenke. \n",
    "    Ihr seht, ich meins ernst und schone niemanden. \n",
    "    Im Gegenteil, hier habt ihr ein Versprechen, \n",
    "    ich werde solche Planen über euch ausbreiten, \n",
    "    dass das Kondenswasser allen Überlegens, \n",
    "    das Brüten eines ganzen Frühlings über euch hereinbricht, \n",
    "    sooft eine leichte Brise die versprochene Behütung, \n",
    "    leicht wie das Versprechen selbst, zu Wellen ähnlich einem Meer im Theater bewegt. \n",
    "    Wollt ihr das? Ich werde euch später, wenn mein Versuch zu Ende ist, danach fragen, \n",
    "    ob ihr das gewollt habt, weil mir schon klar ist, \n",
    "    dass ich mir im vorläufigen Stadium, dem lediglich der Bestellung, \n",
    "    keine klare Antwort abholen kann, \n",
    "    und vertraue auf eure zuneigungsvollen Informationen, \n",
    "    wenn ich, nachdem dies alles vorüber ist, \n",
    "    unter euch mich aufzuhalten die Ehre haben werde. \n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_poet(poem, poets):\n",
    "    \"\"\"predicts artist of song based on artists in corpus\"\"\"\n",
    "    # transform song into vector matrix\n",
    "    poem_vecs = cv.transform(poem)\n",
    "    ynew = poem_vecs.todense()\n",
    "    \n",
    "    print(f\"This classifier predicts the poem to be written by:\\n\")\n",
    "    for i, artist in enumerate(poets):\n",
    "        print(f\"{poets[i]}: {round(m.predict_proba(ynew)[0][i] * 100, 1) }%.\")\n",
    "    poem_pred = m.predict(ynew)[0]\n",
    "    confidence = m.predict_proba(ynew).max()\n",
    "    if confidence > 0.9:\n",
    "        confidence_word = \"definitely\"\n",
    "    elif confidence > 0.7:\n",
    "        confidence_word = \"probably\"\n",
    "    else:\n",
    "        confidence_word = \"maybe\"\n",
    "    print(f\"\\nThis poem is {confidence_word} by {poets[poem_pred]}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier predicts the poem to be written by:\n",
      "\n",
      "H. C. Artmann: 0.0%.\n",
      "Marcel Beyer: 0.0%.\n",
      "Nico Bleutge: 0.0%.\n",
      "Nora Bossong: 0.0%.\n",
      "Ann Cotten: 100.0%.\n",
      "Paul Celan: 0.0%.\n",
      "Oswald Egger: 0.0%.\n",
      "Durs Grünbein: 0.0%.\n",
      "Ernst Jandl: 0.0%.\n",
      "Thomas Kling: 0.0%.\n",
      "Friederike  Mayröcker: 0.0%.\n",
      "Monika Rinck: 0.0%.\n",
      "Ulf Stolterfoht: 0.0%.\n",
      "Uljana Wolf: 0.0%.\n",
      "\n",
      "This poem is definitely by Ann Cotten!\n"
     ]
    }
   ],
   "source": [
    "predict_poet(new_poem2, POETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
