{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Lyrics Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "* Scrape lyrics from lyrics.com and save them on hard drive\n",
    "* Load lyrics into corpus\n",
    "* Create vectors for bag-of-words approach\n",
    "* Train models on lyrics\n",
    "* Predict artist of song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other artists: \"Peaches\", \"Barbra Streisand\", \"Britney Spears\", \"The Velvet Underground\"\n",
    "ARTISTS = [\n",
    "    \"Peaches\",\n",
    "    \"Britney Spears\",\n",
    "    \"Barbra Streisand\",\n",
    "    \"Pavement\",\n",
    "    \"Neutral Milk Hotel\",\n",
    "    \"Sonic Youth\",\n",
    "    \"Stephen Malkmus\",\n",
    "    \"The Velvet Underground\"\n",
    "]  \n",
    "\n",
    "\n",
    "def create_lyrics_corpus(artists):\n",
    "    \"\"\"loads song texts from files and stores lyrics and artist index in seperate lists\"\"\"\n",
    "    complete_lyrics = []\n",
    "    indices = []\n",
    "    for i, artist in enumerate(ARTISTS):\n",
    "        directory = f\"lyrics/{artist.lower().replace(' ', '-')}-lyrics\"\n",
    "        allfiles = os.listdir(directory)\n",
    "        all_lyrics = []\n",
    "        for file in allfiles:\n",
    "            with open(directory + \"/\" + file, \"r\", encoding=\"utf-8\") as f:\n",
    "                song_lyrics = f.read()\n",
    "                all_lyrics.append(song_lyrics)\n",
    "        indices += [i] * len(all_lyrics)\n",
    "        print(artist, len(all_lyrics))\n",
    "        complete_lyrics += all_lyrics\n",
    "    return complete_lyrics, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peaches 67\n",
      "Britney Spears 152\n",
      "Barbra Streisand 428\n",
      "Pavement 79\n",
      "Neutral Milk Hotel 22\n",
      "Sonic Youth 195\n",
      "Stephen Malkmus 29\n",
      "The Velvet Underground 77\n"
     ]
    }
   ],
   "source": [
    "# Store lists into variables, print out number of songs by artist\n",
    "complete_lyrics, indices = create_lyrics_corpus(ARTISTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def vectors_and_df(complete_lyrics, indices):\n",
    "    \"\"\"creates vectors for songs and returns dataframe with songs as word vectors by all artists\"\"\"\n",
    "    cv = TfidfVectorizer(stop_words=\"english\")\n",
    "    cv.fit(complete_lyrics)\n",
    "    corpus_vecs = cv.transform(complete_lyrics)\n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=indices, columns=cv.get_feature_names()), cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>002</th>\n",
       "      <th>03</th>\n",
       "      <th>0h</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>14th</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>...</th>\n",
       "      <th>électrique</th>\n",
       "      <th>étaient</th>\n",
       "      <th>être</th>\n",
       "      <th>הו</th>\n",
       "      <th>יו</th>\n",
       "      <th>ימ</th>\n",
       "      <th>ירו</th>\n",
       "      <th>נו</th>\n",
       "      <th>עו</th>\n",
       "      <th>צו</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows × 10081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    002   03   0h   10  100   12  125  14th   15  150  ...  électrique  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "..  ...  ...  ...  ...  ...  ...  ...   ...  ...  ...  ...         ...   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...         0.0   \n",
       "\n",
       "    étaient  être   הו   יו   ימ  ירו   נו   עו   צו  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..      ...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "7       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7       0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1049 rows x 10081 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(complete_lyrics, indices)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target column\n",
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "\n",
    "models_params = {\n",
    "    \"MultinomialNB\": {},\n",
    "    \"CategoricalNB\": {},\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 200,\n",
    "        \"max_features\": \"auto\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1,\n",
    "    },\n",
    "    \"LogisticRegression\": {\"C\": 1e6},\n",
    "}\n",
    "\n",
    "def train_models(models_params):\n",
    "    \"\"\"trains models on corpus and returns dataframe with scores\"\"\"\n",
    "    scores = {}\n",
    "    for model in models_params:\n",
    "        if model == \"LogisticRegression\":\n",
    "            m = LogisticRegression(**models_params[model])\n",
    "        elif model == \"RandomForestClassifier\":\n",
    "            m = RandomForestClassifier(**models_params[model])\n",
    "        elif model == \"MultinomialNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "        elif model == \"CategoricalNB\":\n",
    "            m = MultinomialNB(**models_params[model])\n",
    "\n",
    "        m.fit(Xtrain, ytrain)\n",
    "        score_train = m.score(Xtrain, ytrain)\n",
    "        score_test = m.score(Xtest, ytest)\n",
    "        scores[f\"{model}\"] = {\n",
    "            \"params\": models_params[model],\n",
    "            \"train score\": score_train,\n",
    "            \"test score\": score_test,\n",
    "        }\n",
    "    return pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denniss/Desktop/Coding/spiced/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalNB</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 200, 'max_f...</td>\n",
       "      <td>0.998808</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>{'C': 1000000.0}</td>\n",
       "      <td>0.998808</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   params  \\\n",
       "MultinomialNB                                                          {}   \n",
       "CategoricalNB                                                          {}   \n",
       "RandomForestClassifier  {'n_estimators': 500, 'max_depth': 200, 'max_f...   \n",
       "LogisticRegression                                       {'C': 1000000.0}   \n",
       "\n",
       "                       train score test score  \n",
       "MultinomialNB             0.460072   0.414286  \n",
       "CategoricalNB             0.460072   0.414286  \n",
       "RandomForestClassifier    0.998808   0.533333  \n",
       "LogisticRegression        0.998808   0.528571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = train_models(models_params)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denniss/Desktop/Coding/spiced/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9990467111534795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on most promising model\n",
    "model = \"LogisticRegression\"\n",
    "m = LogisticRegression(**models_params[model])\n",
    "m.fit(X, y)\n",
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Elton John's \"Can you feel the love tonight\" for prediction\n",
    "new_song = [\n",
    "    \"\"\"\n",
    "    There's a calm surrender\n",
    "    To the rush of day\n",
    "    When the heat of a rolling wave\n",
    "    Can be turned away\n",
    "    An enchanted moment\n",
    "    And it sees me through\n",
    "    It's enough for this restless warrior\n",
    "    Just to be with you\n",
    "    And can you feel the love tonight?\n",
    "    It is where we are\n",
    "    It's enough for this wide-eyed wanderer\n",
    "    That we've got this far\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    How it's laid to rest?\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    There's a time for everyone\n",
    "    If they only learn\n",
    "    That the twisting kaleidoscope\n",
    "    Moves us all in turn\n",
    "    There's a rhyme and reason\n",
    "    To the wild outdoors\n",
    "    When the heart of this star-crossed voyager\n",
    "    Beats in time with yours\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    It is where we are\n",
    "    It's enough for this wide-eyed wanderer\n",
    "    That we've got this far\n",
    "    And can you feel the love tonight? (Tonight)\n",
    "    How it's laid to rest?\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    It's enough to make kings and vagabonds\n",
    "    Believe the very best\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_artist(song_lyrics):\n",
    "    \"\"\"predicts artist of song based on artists in corpus\"\"\"\n",
    "    # transform song into vector matrix\n",
    "    new_song_vecs = cv.transform(new_song)\n",
    "    ynew = new_song_vecs.todense()\n",
    "    \n",
    "    print(f\"This classifier predicts the song to be written by:\\n\")\n",
    "    for i, artist in enumerate(ARTISTS):\n",
    "        print(f\"{artist}: {round(m.predict_proba(ynew)[0][i], 3) * 100}%.\")\n",
    "    song_pred = m.predict(ynew)[0]\n",
    "    confidence = m.predict_proba(ynew).max()\n",
    "    if confidence > 0.9:\n",
    "        confidence_word = \"definitely\"\n",
    "    elif confidence > 0.7:\n",
    "        confidence_word = \"probably\"\n",
    "    else:\n",
    "        confidence_word = \"maybe\"\n",
    "    print(f\"\\nThis song is {confidence_word} by {ARTISTS[song_pred]}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classifier predicts the song to be written by:\n",
      "\n",
      "Peaches: 0.0%.\n",
      "Britney Spears: 43.1%.\n",
      "Barbra Streisand: 56.89999999999999%.\n",
      "Pavement: 0.0%.\n",
      "Neutral Milk Hotel: 0.0%.\n",
      "Sonic Youth: 0.0%.\n",
      "Stephen Malkmus: 0.0%.\n",
      "The Velvet Underground: 0.0%.\n",
      "\n",
      "This song is maybe by Barbra Streisand!\n"
     ]
    }
   ],
   "source": [
    "predict_artist(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
